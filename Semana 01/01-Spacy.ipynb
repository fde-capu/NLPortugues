{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ELGedbTEvV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/imagens/logo_nlportugues.png\"   width=\"150\" align=\"right\">\n",
        "\n",
        "\n",
        "\n",
        "# Lista 1 - spaCy\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8y9-tiGa321"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "387KBr8bTEvY"
      },
      "source": [
        "O [spaCy](\"https://spacy.io\") é uma bilbioteca Python de código fonte [aberto](\"https://github.com/explosion/spaCy\") para Processamento de\n",
        "Linguagem Natural, constantemente atualizada e mantida. Essa biblioteca é capaz de\n",
        "processar diversas línguas, inclusive o português.\n",
        "\n",
        "### Instalação\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8z9R44NUThZb",
        "outputId": "b09d0f2c-f2c7-487c-dc13-50684f0646c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.3.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Installing collected packages: cloudpathlib, weasel, spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.7.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpathlib-0.16.0 spacy-3.7.2 weasel-0.3.3\n"
          ]
        }
      ],
      "source": [
        "%pip install spacy -U"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mAcShOL2PV-i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnieqpc7TEva"
      },
      "source": [
        "Após instalar o pacote spaCy devemos baixar as ferramentas específicas para o português  com o seguinte comando:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U2xrX5-cqK6b",
        "outputId": "0dc8093a-4d2c-4370-c4a9-4f2b8f8617f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-04 02:50:59.575717: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-04 02:50:59.575812: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-04 02:50:59.575853: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-04 02:50:59.587005: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-04 02:51:01.125578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting pt-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.7.0/pt_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.7.0) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.3.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.1.3)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv8ivfCnTEvd"
      },
      "source": [
        "Uma vez que temos o pacote instalado e os módulos para português baixado,  podemos começar a utilizar  o spaCy, importando o pacote e carregando o módulo para português.\n",
        "\n",
        "**Nota:** Caso seus resultados sejam diferentes dos descritos neste texto isso provavelmente significa que você está utilizando uma versão diferente do spaCy, como essa ferramenta é atualizada com frequência não é incomum encontrar discrepâncias nos resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7pr5NflhTEve"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import pt_core_news_sm\n",
        "spacyPT = pt_core_news_sm.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WUa8_JVmTEvf",
        "outputId": "8a924c6b-82e2-4a1d-c1c3-5fc62b193c5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "spacy.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCgdvPK1TEvg"
      },
      "source": [
        "É importante notar que o spaCy assume que os caracteres estão codificados no formato utf-8.  O primeiro passo portanto é gerar uma entrada nesse formato e submetê-la ao módulo carregado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o7Q9inqTEvh",
        "outputId": "496ce3f4-a138-4983-881c-8fe0766835b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mais vale um asno que me carregue que um cavalo que me derrube."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "entrada = spacyPT(\"Mais vale um asno que me carregue que um cavalo que me derrube.\")\n",
        "entrada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhoKGbccTEvi"
      },
      "source": [
        "### Tokenização (itemização)\n",
        "\n",
        "A entrada que acabamos de gerar é uma sequência iterável de tokens (itens,  \n",
        "ou instâncias de palavras). Se quisermos verificar qual o texto contido nessa\n",
        "sequência iterável,  usamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HZFtnbHUTEvj",
        "outputId": "120d59a3-8ee8-42ee-e264-7979b4c94cce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mais vale um asno que me carregue que um cavalo que me derrube.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "entrada.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5_1tofrTEvk"
      },
      "source": [
        "Se quisermos dividir a entrada em token,  podemos utilizar o método __split__:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG2rMfWYTEvm",
        "outputId": "f6b63d75-9e5d-4ce9-d2df-23f2ede53b64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mais',\n",
              " 'vale',\n",
              " 'um',\n",
              " 'asno',\n",
              " 'que',\n",
              " 'me',\n",
              " 'carregue',\n",
              " 'que',\n",
              " 'um',\n",
              " 'cavalo',\n",
              " 'que',\n",
              " 'me',\n",
              " 'derrube.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "entrada.text.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSpMSZrzTEvm"
      },
      "source": [
        "Note que o ponto  final foi absorvido pela palavra;  o mesmo teria acontecido com\n",
        "outros sinais de pontuação a utilizar  o método __split__. Para separar a pontuação\n",
        "das palavras utilizamos a  tokenização implícita realizada pelo comando __in__:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyjtxYEMTEvm",
        "outputId": "2548a58b-d83b-4389-b423-5917b32da310"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Mais, vale, um, asno, que, me, carregue, que, um, cavalo, que, me, derrube, .]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "[token for token in entrada]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9Fy34xoTEvn"
      },
      "source": [
        "Note que os streams não estão entre aspas,  pois na realidade esta lista contém uma sequência de objetos da classe __Token__.\n",
        "\n",
        "Se o objetivo é obter uma lista de Strings,  podemos proceder da seguinte maneira.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5I-X9vJTEvn",
        "outputId": "c5472458-5cae-4d96-b9de-2fd399c53568"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mais',\n",
              " 'vale',\n",
              " 'um',\n",
              " 'asno',\n",
              " 'que',\n",
              " 'me',\n",
              " 'carregue',\n",
              " 'que',\n",
              " 'um',\n",
              " 'cavalo',\n",
              " 'que',\n",
              " 'me',\n",
              " 'derrube',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "[token.text for token in entrada]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EC2dnbRTEvp"
      },
      "source": [
        "E para eliminar totalmente a pontuação da lista,  é só restringirr  a sua criação usando __is_punct__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkTxxfstTEvp",
        "outputId": "2f882634-6d82-4b5b-fa9e-2c39049a1111"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mais',\n",
              " 'vale',\n",
              " 'um',\n",
              " 'asno',\n",
              " 'que',\n",
              " 'me',\n",
              " 'carregue',\n",
              " 'que',\n",
              " 'um',\n",
              " 'cavalo',\n",
              " 'que',\n",
              " 'me',\n",
              " 'derrube']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "[token.text for token in entrada if not token.is_punct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJHmrb02TEvp"
      },
      "source": [
        "O spaCy já vem treinado para realizar etiquetagem morfossintática (PoS tagging),  o que pode ser mostrado da seguinte maneira."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfxFqqCbTEvq",
        "outputId": "69900df5-07d3-4180-b22d-8d8534c69e18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mais', 'ADV'),\n",
              " ('vale', 'VERB'),\n",
              " ('um', 'DET'),\n",
              " ('asno', 'NOUN'),\n",
              " ('que', 'PRON'),\n",
              " ('me', 'PRON'),\n",
              " ('carregue', 'VERB'),\n",
              " ('que', 'SCONJ'),\n",
              " ('um', 'DET'),\n",
              " ('cavalo', 'NOUN'),\n",
              " ('que', 'PRON'),\n",
              " ('me', 'PRON'),\n",
              " ('derrube', 'VERB'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "[(token.text, token.pos_) for token in entrada]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icqdYydXTEvq"
      },
      "source": [
        "A assistência do etiquetador nos permite fazer buscas bastante sofisticadas. Por exemplo podemos buscar os lemas de todos os verbos encontrados  na sentença."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAUS7nCCTEvr",
        "outputId": "0227e9bb-396c-4b0b-bb73-112dd4dd7d77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['valer', 'carregar', 'derrube']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "[token.lemma_ for token in entrada if token.pos_ == 'VERB']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Mjy3wMTEvr"
      },
      "source": [
        "Os lemas de verbos conjugados nos fornecem  a sua forma infinitiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0bum0sCTEvs"
      },
      "source": [
        "### Reconhecimento de entidades nomeadas\n",
        "\n",
        "A biblioteca já vem treinada com um  mecanismo que permite o reconhecimento de\n",
        "entidades nomeadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFmJt1pYTEvs",
        "outputId": "255afff1-c563-4a75-8420-1b506bcded67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(CBF, Comitê de Apelações da FIFA, Neymar, Copa América, Conmebol)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(CBF, 'ORG'),\n",
              " (Comitê de Apelações da FIFA, 'ORG'),\n",
              " (Neymar, 'PER'),\n",
              " (Copa América, 'MISC'),\n",
              " (Conmebol, 'ORG')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "texto2 = spacyPT(\"A CBF fez um pedido de análise ao Comitê de Apelações da FIFA a fim de diminuir a pena do atacante Neymar, suspenso da Copa América pela Conmebol.\")\n",
        "print(texto2.ents)\n",
        "[(entidade,entidade.label_) for entidade in texto2.ents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugIP-xrPTEvt"
      },
      "source": [
        "___________________________\n",
        "# <font color='blue'>  Questão 1 </font>\n",
        "\n",
        "Utilizando o spacy, extraia o nome dos personagens presentes no terceiro capitulo da obra \"Mémorias postumas de Brás Cubas\" de Machado de Assis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NuRJF6YcTEvt",
        "outputId": "f37e84d3-4bb3-4ebf-db48-05f2c4589f9a",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mas, já que falei nos meus dois tios, deixem-me fazer aqui um curto esboço genealógico.        O fundador de minha família foi um certo Damião Cubas, que floresceu na primeira metade do século XVIII. Era tanoeiro de ofício, natural do Rio de Janeiro, onde teria morrido na penúria e na obscuridade, se somente exercesse a tanoaria. Mas não; fez-se lavrador, plantou, colheu, permutou o seu produto por boas e honradas patacas, até que morreu, deixando grosso cabedal a um filho, o licenciado Luís Cubas. Neste rapaz é que verdadeiramente começa a série de meus avós -- dos avós que a minha família sempre confessou -  porque o Damião Cubas era afinal de contas um tanoeiro, e talvez mau tanoeiro, ao passo que o Luís Cubas estudou em Coimbra, primou no Estado, e foi um dos amigos particulares do vice-rei conde da Cunha.        Como este apelido de Cubas lhe cheirasse excessivamente a tanoaria, alegava meu pai, bisneto do Damião, que o dito apelido fora dado a um cavaleiro, herói nas jornadas da Africa, em prêmio da façanha que praticou arrebatando trezentas cubas ao mouros. Meu pai era homem de imaginação; escapou à tanoaria nas asas de um calembour. Era um bom caráter, meu pai, varão digno e leal como poucos. Tinha, é verdade, uns fumos de pacholice; mas quem não é um pouco pachola nesse mundo? Releva notar que ele não recorreu à inventiva senão depois de experimentar a falsificação; primeiramente, entroncou-se na família daquele meu famoso homônimo, o capitão-mor Brás Cubas, que fundou a vila de São Vicente, onde morreu em 1592, e por esse motivo é que me deu o nome de Brás. Opôs-se-lhe, porém, a família do capitão-mor, e foi então que ele imaginou as trezentas cubas mouriscas.        Vivem ainda alguns membros de minha família, minha sobrinha Venância, por exemplo, o lírio-do-vale, que é a flor das damas do seu tempo; vive o pai, o Cotrim, um sujeito que... Mas não antecipemos os sucessos; acabemos de uma vez com o nosso emplasto. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "cap_3_bras_cubas = \"Mas, já que falei nos meus dois tios, deixem-me fazer aqui um curto esboço genealógico.        O fundador de minha família foi um certo Damião Cubas, que floresceu na primeira metade do século XVIII. Era tanoeiro de ofício, natural do Rio de Janeiro, onde teria morrido na penúria e na obscuridade, se somente exercesse a tanoaria. Mas não; fez-se lavrador, plantou, colheu, permutou o seu produto por boas e honradas patacas, até que morreu, deixando grosso cabedal a um filho, o licenciado Luís Cubas. Neste rapaz é que verdadeiramente começa a série de meus avós -- dos avós que a minha família sempre confessou -  porque o Damião Cubas era afinal de contas um tanoeiro, e talvez mau tanoeiro, ao passo que o Luís Cubas estudou em Coimbra, primou no Estado, e foi um dos amigos particulares do vice-rei conde da Cunha.        Como este apelido de Cubas lhe cheirasse excessivamente a tanoaria, alegava meu pai, bisneto do Damião, que o dito apelido fora dado a um cavaleiro, herói nas jornadas da Africa, em prêmio da façanha que praticou arrebatando trezentas cubas ao mouros. Meu pai era homem de imaginação; escapou à tanoaria nas asas de um calembour. Era um bom caráter, meu pai, varão digno e leal como poucos. Tinha, é verdade, uns fumos de pacholice; mas quem não é um pouco pachola nesse mundo? Releva notar que ele não recorreu à inventiva senão depois de experimentar a falsificação; primeiramente, entroncou-se na família daquele meu famoso homônimo, o capitão-mor Brás Cubas, que fundou a vila de São Vicente, onde morreu em 1592, e por esse motivo é que me deu o nome de Brás. Opôs-se-lhe, porém, a família do capitão-mor, e foi então que ele imaginou as trezentas cubas mouriscas.        Vivem ainda alguns membros de minha família, minha sobrinha Venância, por exemplo, o lírio-do-vale, que é a flor das damas do seu tempo; vive o pai, o Cotrim, um sujeito que... Mas não antecipemos os sucessos; acabemos de uma vez com o nosso emplasto. \"\n",
        "cap_3_bras_cubas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CG6FJniETEvu",
        "outputId": "d6b62ef7-19f5-4db1-ae7e-062ce87f5ca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Damião Cubas,\n",
              " Luís Cubas,\n",
              " Damião Cubas,\n",
              " Luís Cubas,\n",
              " conde da Cunha,\n",
              " Damião,\n",
              " Brás Cubas]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "personagens = spacyPT(cap_3_bras_cubas)\n",
        "[personagem for personagem in personagens.ents if personagem.label_ == 'PER']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ozEx2k4RUf0h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujmz8q2jTEvv"
      },
      "source": [
        "Quais destas repostas estão corretas?  Quais personagens estão faltando?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AxVwxhJTEvv"
      },
      "source": [
        "- \"conde da Cunha\" deveria ser \"vice-rei conde da Cunha\".\n",
        "- O \"pai\" é também um personagem, embora não esteja notado como entidade inicialmente, mas depois denominado \"Cotrim\".\n",
        "- O narrador é também um personagem implícito, dito homônimo \"Brás Cubas\"; então \"Brás Cubas\" poderia ser apresentado duas vezes, para desambiguação.\n",
        "- \"Venância\" simplesmente não apareceu.\n",
        "- A aparição repetida de alguns dos nomes seria ou não desejada dependendo do contexto de uso; mesmo assim, neste momento, segunda análise seria necessária para notar que \"Damião Cubas\" e \"Damião\" correspondem ao mesmo personagem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3juZmY0jTEvx"
      },
      "source": [
        "# <font color='blue'>  Questão 2 </font>\n",
        "\n",
        "Extraia todos os pronomes deste capitulo.\n",
        "\n",
        "_____________\n",
        "**<font color='red'> Sua resposta aqui </font>**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrMsM33ZTEvw"
      },
      "outputs": [],
      "source": [
        "#Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bW_x8XHTEvx"
      },
      "source": [
        "# <font color='blue'>  Questão 3 </font>\n",
        "Utilize os visualizadores para explorar o mapa de dependencias de uma frase a sua escolha deste capitulo.\n",
        "https://spacy.io/usage/visualizers\n",
        "\n",
        "Você pode acessar diretamente uma frase especifica ao utilizar o gerador \"sents\", por exemplo:\n",
        "\n",
        "```python\n",
        "frases = [frase for frase in texto.sents]\n",
        "frases[2]\n",
        "\n",
        "\n",
        "Era tanoeiro de ofício, natural do Rio de Janeiro LOC , onde teria morrido na penúria e na obscuridade, se somente exercesse a tanoaria.\n",
        "```\n",
        "\n",
        "\n",
        "_______________\n",
        "\n",
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqUiCknrTEvy"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AWMKGioTEvy"
      },
      "outputs": [],
      "source": [
        "#Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmCGp6yNTEvz"
      },
      "source": [
        "# Fontes\n",
        "Tanto o capitulo utilizado nesta aula quanto a obra completa fazem parte do dominio publico e podem ser encontrados em http://www.dominiopublico.gov.br/download/texto/bv000215.pdf"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of 01-Spacy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv_tutorial",
      "language": "python",
      "name": ".venv_tutorial"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}